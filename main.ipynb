{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection with YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this jupyter notebook we'll be implementing face detection with ultralytics' YOLOv5 implementation using the PyTorch deep learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Dependency Acquisition](##Dependency-Acquisition)\n",
    "   1. [Dependency Installation](###Dependency-Installation)\n",
    "   2. [Dependency Import](###Dependency-Import)\n",
    "2. [Dataset Collection](##Dataset-Collection)\n",
    "   1. [Image Capture](###Image-Capture)\n",
    "   2. [Image Labelling](###Image-Labelling)\n",
    "3. [Model Re-training](##Model-Re-training)\n",
    "4. [Inference](##Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from torchvision) (1.23.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests->torchvision) (1.26.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultralytics' YOLOv5 github repo clone and dependency installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloning github repo...\n",
      "installing YOLOv5 requirements...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 5)) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 6)) (1.23.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 8)) (9.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 10)) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 11)) (1.9.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 12)) (1.12.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 13)) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 14)) (4.64.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 15)) (3.19.4)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 18)) (2.10.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 23)) (1.4.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 24)) (0.11.2)\n",
      "Requirement already satisfied: ipython in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 38)) (8.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 39)) (5.9.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from -r requirements.txt (line 40)) (0.1.1.post2207130030)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (4.35.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 14)) (0.4.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.47.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (56.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (3.0.30)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (5.3.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.18.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.4.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (2.13.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 38)) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.10.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (2.0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "print(\"cloning github repo...\")\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "print(\"installing YOLOv5 requirements...\")\n",
    "!cd yolov5 & pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelImg (labelling tool) installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloning github repo...\n",
      "Installing LabelImg requirements & finalizing installation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'labelImg'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyqt5\n",
      "  Downloading PyQt5-5.15.7-cp37-abi3-win_amd64.whl (6.8 MB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp38-cp38-win_amd64.whl (3.6 MB)\n",
      "Collecting PyQt5-sip<13,>=12.11\n",
      "  Downloading PyQt5_sip-12.11.0-cp38-cp38-win_amd64.whl (78 kB)\n",
      "Collecting PyQt5-Qt5>=5.15.0\n",
      "  Downloading PyQt5_Qt5-5.15.2-py3-none-win_amd64.whl (50.1 MB)\n",
      "Installing collected packages: PyQt5-sip, PyQt5-Qt5, pyqt5, lxml\n",
      "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.11.0 lxml-4.9.1 pyqt5-5.15.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\fouadhanani\\virtualenvs\\deep-learning\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "print(\"cloning github repo...\")\n",
    "!git clone https://github.com/tzutalin/labelImg\n",
    "print(\"Installing LabelImg requirements & finalizing installation...\")\n",
    "!pip install pyqt5 lxml --upgrade\n",
    "!cd labelImg && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import uuid\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start capturing images using our camera, let's create some directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images_path = os.path.join(\"dataset\", \"images\")\n",
    "if not os.path.exists(dataset_images_path):\n",
    "    os.makedirs(dataset_images_path)\n",
    "    print(f\"{dataset_images_path} created successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels_path = os.path.join(\"dataset\", \"labels\")\n",
    "if not os.path.exists(dataset_labels_path):\n",
    "    os.makedirs(dataset_labels_path)\n",
    "    print(f\"{dataset_labels_path} created successfully...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start capturing some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image of label face to dataset\\images\\face-e04fd1e5-1d5f-11ed-928e-a24242e2012e.jpg\n",
      "so far there is 1 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-e28f9d3f-1d5f-11ed-892e-a24242e2012e.jpg\n",
      "so far there is 2 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-e3a37dde-1d5f-11ed-9d42-a24242e2012e.jpg\n",
      "so far there is 3 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-e52a0995-1d5f-11ed-bb55-a24242e2012e.jpg\n",
      "so far there is 4 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-e63bb925-1d5f-11ed-8c0e-a24242e2012e.jpg\n",
      "so far there is 5 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-e7440156-1d5f-11ed-82d5-a24242e2012e.jpg\n",
      "so far there is 6 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-e891bf51-1d5f-11ed-b0c0-a24242e2012e.jpg\n",
      "so far there is 7 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-e98ad1f8-1d5f-11ed-b311-a24242e2012e.jpg\n",
      "so far there is 8 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-eaf8e78a-1d5f-11ed-8601-a24242e2012e.jpg\n",
      "so far there is 9 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-ec05ad08-1d5f-11ed-8656-a24242e2012e.jpg\n",
      "so far there is 10 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-efc9dba4-1d5f-11ed-8701-a24242e2012e.jpg\n",
      "so far there is 11 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-f5410917-1d5f-11ed-b10e-a24242e2012e.jpg\n",
      "so far there is 12 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-f881720d-1d5f-11ed-85d4-a24242e2012e.jpg\n",
      "so far there is 13 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-fc03c51b-1d5f-11ed-80cb-a24242e2012e.jpg\n",
      "so far there is 14 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-fcf7dc55-1d5f-11ed-b259-a24242e2012e.jpg\n",
      "so far there is 15 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-fd8a741a-1d5f-11ed-b94f-a24242e2012e.jpg\n",
      "so far there is 16 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-fe8d4bea-1d5f-11ed-bb94-a24242e2012e.jpg\n",
      "so far there is 17 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-ff864b66-1d5f-11ed-b963-a24242e2012e.jpg\n",
      "so far there is 18 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-00b79723-1d60-11ed-af4e-a24242e2012e.jpg\n",
      "so far there is 19 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-01f7abf3-1d60-11ed-95d6-a24242e2012e.jpg\n",
      "so far there is 20 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-029d5064-1d60-11ed-b38f-a24242e2012e.jpg\n",
      "so far there is 21 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-0336f4ed-1d60-11ed-b75c-a24242e2012e.jpg\n",
      "so far there is 22 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-042dc9e0-1d60-11ed-95e8-a24242e2012e.jpg\n",
      "so far there is 23 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-05182412-1d60-11ed-a761-a24242e2012e.jpg\n",
      "so far there is 24 images of face and 0 images of noface\n",
      "saving image of label face to dataset\\images\\face-063a8d73-1d60-11ed-95f7-a24242e2012e.jpg\n",
      "so far there is 25 images of face and 0 images of noface\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "face, noface = 0, 0\n",
    "label = \"face\"\n",
    "\n",
    "while True:\n",
    "    status, frame = capture.read()\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    # if the \"f\" key is pressed then switch the image label (face <--> noface)\n",
    "    if key & 0xFF == ord('f'):\n",
    "        label = \"face\" if label == \"noface\" else \"noface\"\n",
    "        print(f\"switching to the label {label}\")\n",
    "\n",
    "    # if the \"s\" key is pressed then save image\n",
    "    if key & 0xFF == ord('s'):\n",
    "        image_path = os.path.join(dataset_images_path, f\"{label}-{uuid.uuid1()}.jpg\")\n",
    "        cv2.imwrite(image_path, frame)\n",
    "        print(f\"saving image of label {label} to {image_path}\")\n",
    "        if label == \"face\":\n",
    "            face += 1\n",
    "        else:\n",
    "            noface += 1\n",
    "        print(f\"so far there is {face} images of face and {noface} images of noface\")\n",
    "\n",
    "    # if the \"q\" key is pressed then stop\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using LabelImg to label our dataset of images, the following commands will run the labelImg software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: labelImg.py [-h] [image_dir] [class_file] [save_dir]\n",
      "labelImg.py: error: unrecognized arguments: to run in a terminal (copy everything and leave out the ! and make sure you're connected to the right kernel)\n"
     ]
    }
   ],
   "source": [
    "!cd labelImg & python labelImg.py # it's better to run in a terminal (copy everything and leave out the \"!\" and make sure you're connected to the right kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous labelling action only applies to the images with faces on it, for the images with no faces on them we'll create labels for them manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(dataset_images_path)\n",
    "for image in images:\n",
    "    image_name = image.replace(\".jpg\", \"\")\n",
    "    label_path = os.path.join(dataset_labels_path, f\"{image_name}.txt\")\n",
    "    if not os.path.exists(label_path):\n",
    "        with open(label_path, \"w\") as file:\n",
    "            file.write(\"0, 0, 0, 0, 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final step before launching training, we have to create a `dataset.yaml` file inside the yolov5 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = None\n",
    "with open(os.path.join(dataset_labels_path, \"classes.txt\"), \"r\") as file:\n",
    "    classes = list(map(lambda classname: classname.replace(\"\\n\", \"\"), file.readlines()))\n",
    "\n",
    "with open(os.path.join(\"yolov5\", \"dataset.yaml\"), \"w\") as file:\n",
    "    file.write(\"path: ../dataset\\n\")\n",
    "    file.write(\"train: images\\n\")\n",
    "    file.write(\"val: images\\n\")\n",
    "    file.write(f\"nc: {len(classes)}\\n\")\n",
    "    file.write(f\"names: {classes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Re-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start training, we run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 && python train.py --img 320 --batch 16 --epochs 100 --data dataset.yaml --weights yolov5s.pt --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start using the model, we'll have to load the model as a custom model so we could load the learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = os.path.join(\"yolov5\", \"runs\", \"train\")\n",
    "weights = os.listdir(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\fouadhanani/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-8-16 Python-3.8.10 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7053277 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "optimized_weights_path = os.path.join(weights_path, weights[-1], 'weights', 'last.pt')\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=optimized_weights_path, force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = \"https://img.freepik.com/photos-premium/voyageur-vietnamien-deux-hommes-prenant-selfie-dans-ville-etrangere_264197-5448.jpg\"\n",
    "img = \"https://static.techspot.com/images2/news/bigimage/2020/06/2020-06-08-image-8-j_1100.webp\"\n",
    "results = model(img)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    status, frame = capture.read()\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "    cv2.imshow(\"frame\", np.squeeze(results.render()))\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    # if the \"q\" key is pressed then stop\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('deep-learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bad07c065a6a5c4003d0757fda1dfce8dc4496721624ee611e6413d25738300b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
